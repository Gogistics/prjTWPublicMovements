need
using
predicate
supports
PathFilter
split_input
Path
formats
missing
time
Raises
ReadBuffer
mapper_spec
Accepts
objects
deep
COUNTER_IO_READ_BYTE
opened
Skipping
basestring
_buffer_size
shown
number
requested
Index
isinstance
COUNTER_IO_READ_MSEC
prefix
each
bin
separator
Inherit
mapper_sec
A
de
stops
could
current
left
tell
may
d
readline
a
GoogleCloudStorageInputReader
Inc
join
_slice_ctx
InputReaders
s
library
configuration
classmethod
Unless
_filenames
_bucket_itr
docs
distributed
by
apache
splitting
has
close
software
cloudstorage
invalid
future
any
permissions
__getstate__
be
Initialize
AS
append
get
Cloud
filenames
COUNTER_FILE_READ
_record_reader
names
fewer
example
OBJECT_NAMES_PARAM
set
Returns
SliceContext
name
An
implied
KIND
all
law
job_config
You
at
assigned
equal
__all__
num_files
input_reader
never
which
retrieve
there
an
reason
no
buffer_size
otherwise
of
errors
on
only
path_filter
LevelDB
listed
_cur_handle
_delimiter
Required
params_cp
DELIMITER_PARAM
http
will
COUNTER_FILE_MISSING
records
_bucket
raised
mapper
express
ValueError
WITHOUT
mapreduce
objectname
unless
CONDITIONS
OF
files
No
my
OR
hasattr
params_to_json
additional
nd
obj
iter
EOFError
warning
individual
CloudStorage
every
type
ext
related
buffer
python
input_reader_params
level
more
when
listbucket
required
_path_filter
_next_file
such
int
IS
matching
signifies
If
this
Optional
In
expansion
writing
limitations
applicable
prefixes
Bad
super
path
read
GCSRecordInputReader
treated
it
extend
list
readers
params
interface
suffix
GCS
_account_id
to_json
bucket_name
Delimiter
implementation
PATH_FILTER_PARAM
removed
found
from_json
handle
pop
map_job
_bucket_iter
validate
shard_count
although
EOF
copy
ends
cls
To
under
_index
ImportError
expanded
__class__
content
__init__
split
read_buffer_size
specify
BUCKET_NAME_PARAM
bucket
next
data
use
logged
JobConfig
StopIteration
The
Apache
usr
Input
dumps
seek
either
string
documentation
doc
slice
part
to
duplication
must
Filename
after
shards
Internal
st
instance
Version
agreed
loads
index
shallow
Validate
providing
size
Entries
all_filenames
that
input
shard_filenames
reader
str
than
Read
existent
result
can
governing
www
multiple
too
_STUB
__name__
you
See
ordered
InputReader
Google
handler
via
accept
open
are
accepted
file
params_from_json
json_params
form
exhausted
like
__dict__
many
record
obtain
start
language
some
might
google
file_stat
range
NotFoundError
encountered
org
mode
twice
before_iter
slice_ctx
RecordsReader
Copyright
api
Object
covered
options
BadReaderParamsError
slash
BUFFER_SIZE_PARAM
dictionary
env
len
before_slice_ctx
should
delimiter
Next
License
directory
GCSInputReader
but
endswith
enable
All
compliance
used
been
LICENSE
granularity
reader_params
_ACCOUNT_ID_PARAM
goes
account_id
status
Find
NotImplementedError
logging
format
Only
WARRANTIES
Storage
default
pickle
_JSON_PICKLE
match
filter
dict
other
have
specific
one
state
currently
licenses
object
Args
validate_bucket_name
shard
dir
during
Licensed
ANY
error
File
the
__str__
BASIS
Non
appengine
skipped
specification
filename
start_time
_STRING_MAX_FILES_LISTED
incr
