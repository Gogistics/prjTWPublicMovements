need
using
store
KeyValueFileOutputWriter
no_dup
gc
particular
supports
creates
chance
_FILES_API_FLUSH_SIZE
formats
MapreduceState
missing
time
references
Raises
_GoogleCloudStorageOutputWriter
created
Increment
mapper_spec
shard_attempt
fs
subclassed
But
content_type
_flush_size
duplicate
once
serialize
cloudstorage_api
GoogleCloudStorage
parent
izable
number
shows
Utility
file_pool
initialization
isinstance
prefix
gcs_next_offset
RecordsPool
gs
bin
each
big
spec
MapReduce
Inherit
GS_BUCKET_NAME_PARAM
A
exclusive
request_filenames
_get_filesystem
interleaving
BlobstoreRecordsOutputWriter
instances
renamed
advised
with_statement
sync
could
mappings
Create
write
current
tell
set_key
do
outputs
$id
KeyValueBlobstoreOutputWriter
warnings
ensure
look
f
deprecated
d
may
Finalize
keys
_writer_state
a
Implementors
n
Inc
join
w
v
_get_filename
output_sharding
new
t
s
library
base
shard_state
Get
allowed_keys
configuration
_pad_block
classmethod
returned
Helper
Unless
x
methods
GS_ACL_PARAM
FileOutputWriterBase
docs
least
writable
exception
normal
distributed
by
apache
boundary
has
close
software
cloudstorage
would
invalid
Should
any
permissions
processing
writer_state
key
be
initialize
Initialize
AS
append
get
Cloud
filenames
_seg_index
indicating
_no_dup
names
containing
collect
update
named
Flush
_JSON_GCS_BUFFER
At
set
RESULT_SUCCESS
Returns
finalizing
get_filenames
possible
following
Write
name
CloudStorageOutputWriter
implied
An
KIND
List
all
reached
law
GS_FILESYSTEM
_create_file
You
_record_writer
Template
assigned
data_length
at
New
finished
gs_acl
Error
_streaming_buffer
neither
__all__
message
seg
expected
__append
which
flush
Writer
an
there
Fetches
compatability
Whether
job_id
_NO_DUPLICATE
CONTENT_TYPE_PARAM
OUTPUT_SHARDING_PARAM
they
_SEG_PREFIX
lower
reason
configured
no
Filesystem
substitution
persist
operation
of
$name
errors
_recover
Files
given
basename
lifecycle
ctx
empty
combine
only
on
_LAST_SEG_INDEX
_supports_slice_recovery
LevelDB
final
gae
support
_get_params
done
$seg
job
bad
MR
Every
Required
http
then
will
__future__
records
GoogleCloudStorageOutputWriter
JsonMixin
bigger
subject
mapper
ValueError
$num
express
across
WITHOUT
mapreduce
params_diff
str_buf
supported
sharding
CONDITIONS
OUTPUT_SHARDING_NONE
OF
COUNTER_IO_WRITE_MSEC
closed
naming_format
internal
BadWriterParamsError
null
completed
files
mr
unknown
No
finalize_job
OR
_exclusive
On
hasattr
per
specified
new_writer
method
retry
octet
filesystem
warning
produce
apply
single
save
location
gae_mr_tmp
contains
actually
type
ext
python
buffer
_RECORD_OVERHEAD_BYTES
more
level
Context
request
when
ID
value
none
writes
writer
required
live
tstate
appropriate
such
int
means
cStringIO
NAMING_FORMAT_PARAM
IS
_GoogleCloudStorageRecordOutputWriter
BlobstoreOutputWriterBase
describing
flag
called
leveldb
If
this
Optional
_buffer
In
Type
writing
limitations
Stored
applicable
prefixes
Bad
smaller
was
KB
id
super
risk
StringIO
__enter__
Can
treated
compute
msec
getvalue
_append_buffer
application
it
added
impl
delimiters
acl
into
_get_output_sharding
list
params
suffix
GCS
flush_size_chars
proto
io
_account_id
Finalized
two
to_json
bucket_name
implementation
KeyValue
mapreduce_state
Naming
_ctx
from_json
These
no_duplicate
passed
_create
wrote
checks
its
counters
Expecting
validate
retried
finalize
feature
boolean
filename_suffix
copy
template
chunks
duplicates
cls
contents
To
under
iteritems
ImportError
__class__
log
register_pool
When
__init__
own
Encode
we
_filename
_JSON_SEG_INDEX
Base
_supports_shard_retry
idempotent
next
BUCKET_NAME_PARAM
bucket
data
use
finalization
last_seg_index
useless
meta
__exit__
Apache
The
create_filename
written
specifed
usr
previous
dumps
_MR_TMP
finalized
implemented
blobstore
medium
combined
up
num
get_pool
either
aligns
streaming_buffer
string
doc
retries
writers
slice
part
arbitrary
to
allow_old
OUTPUT_FILESYSTEM_PARAM
MapperSpec
_TMP_FILE_NAMING_FORMAT
substitute
Output
padding
must
result_status
_JSON_NO_DUP
shards
values
Allow
tmp
Internal
exclusive_lock
parameters
Invalid
instance
Version
shared
loads
agreed
index
segs
so
Validate
transient
Pool
saved
providing
logic
modified
size
$attempt
that
syntax
input
subdicationary
str
than
due
case
got
rsplit
attempt
result
valid
model
can
generate
file_service_pb
governing
www
about
_seg_valid_length
strings
_State
Shard
kwargs
mapreduce_spec
request_filename
So
KeyError
json
compatible
_size
Generates
last_index
output_writer_class
multiple
too
_get_offset_from_gcs
separate
seg_prefix
finalized_filenames
_STUB
helper
__name__
FileRecordsOutputWriter
you
See
recovery
threshold
TransientShardState
goog
_copy2
anything
State
provided
actual
usage
operations
mismatch
Google
success
handler
BlobstoreOutputWriter
out
_request_filename
tuple
applies
Obtain
ACL_PARAM
After
DEFAULT_NAMING_FORMAT
COUNTER_IO_WRITE_BYTES
info
serializaton
Data
open
are
mime_type
directories
set_value
file
Init
false
Too
output_writer
_force_close
information
extra
flushed
like
without
create
placeholders
many
record
present
OutputWriter
nor
atype
obtain
flushes
mime
language
writer_spec
outside
stream
bytes
google
mapping
org
This
mode
version
serialized
traceback
length
maintains
starting
FILESYSTEMS
Copyright
api
giving
simplify
seg_index
formatting
options
_generate_filename
slash
len
env
dictionary
access
should
shard_number
process
Validates
License
RecordsWriter
directory
find_all_by_mapreduce_state
successfully
cloud
Constructor
seg_filename
buf
based
Neither
initializer
Abstract
allowed
but
old
substitutions
compliance
used
OUTPUT_SHARDING_INPUT_SHARDS
been
function
mapreduce_id
LICENSE
json_util
mr_spec
were
next_seg_index
dedicated
yielded
init_job
returns
FileOutputWriter
metadata
_VALID_LENGTH
ShardState
_ACCOUNT_ID_PARAM
account_id
Directories
NotImplementedError
logging
format
Append
Only
WARRANTIES
FileClosedError
Storage
TypeError
default
pickle
_FILES_API_MAX_SIZE
output
_get_finalized_filename
dict
Any
other
specific
have
suffixes
issue
slices
MapreduceSpec
one
state
Got
contained
Buffer
licenses
object
Creates
API
validate_bucket_name
Args
subdictionary
share
parameter
shard
pool
during
Licensed
_GoogleCloudStorageKeyValueOutputWriter
For
How
records_pool
exist
retrieved
find
gs_bucket_name
error
check
ANY
File
BLOBSTORE_FILESYSTEM
the
_FilePool
BASIS
get_file_name
appengine
applied
specification
context
start_time
filename
assume
user
get_blob_key
storage
