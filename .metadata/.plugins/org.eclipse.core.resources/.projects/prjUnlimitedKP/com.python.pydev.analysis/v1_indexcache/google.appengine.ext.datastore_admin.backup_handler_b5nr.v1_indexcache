ConfirmAbortBackupHandler
has_doublevalue
InvalidFileNameError
backup_info_path
schema_aggregation_pool
creates
HEAD
FetchQueues
Kind
CreateXsrfToken
time
Raises
created
_get_parent_key
urlencode
mapreduce_detail
$
create_backup
urllib
Raised
aggregation
Do
Deletes
DatastoreAdminClient
GET
drop_empty_files
target_app
prefix
bin
each
A
M
InvalidArgumentError
has_referencevalue
getElementsByTagName
bucket_elements
backup_result
Authorization
token
MAX_BLOBS_PER_DELETE
IsKindNameVisible
side
R
_
X
finalize_backup_info
backup_abort
f
d
e
keys
InvalidParameterError
DoBackupDeleteHandler
a
delete_backup_files
StringListProperty
meaning
join
USER
register
w
new
GS
including
s
r
sequence
p
base
testing
kind_name
TEST_WRITE_FILENAME_PREFIX
GD_POSTALADDRESS
x
job_operation
other_property
exception
entity
distributed
apache
has
DoBackupAbortHandler
software
Backup
invalid
FLOAT
gs_warning
description
permissions
processing
TaskQueueMode
initialize
key_str
Initialize
append
AS
Cloud
filenames
other_backup_info_files
display
code
run_as_a_service
node
Updates
names
urlfetch
DatastoreAdminOperation
update
Field
Import
As
set_status
STATUS_COMPLETED
response
TextProperty
LINK
name
implied
An
mappers
BUCKET_PATTERN
bak_file
law
GS_FILESYSTEM
requested_backup_ids
updates
Error
main
self_property
itervalues
POST
is_repeated
input_reader
flush
which
_url
GsBucketURL
__shard_id
jobs
lower
verify
otherwise
aggregates
property_proto
rpc
given
ctx
empty
tokens
aggregated
populate_entity_schema
parametrs
completed_jobs
auto_now_add
INPUT_READER
job
MR
Required
http
test_file
RenderToResponse
will
__future__
mapped
upon
JsonMixin
set_max_rows
xsrf_error
_write_backup_info
mapper
childNodes
ValueError
express
GD_WHEN
is_list
CATEGORY
tests
Unsupported
OF
original_app_warning
EntityProto
GEO_POINT
denied
No
OR
On
per
method
capabilities
confirm_restore_from_backup
output_writers
headers
MAX_KEYS_LIST_SIZE
blobs_info
contains
get_backup_files
EntityTypeInfo
__kind
type
ext
changed
python
remainder
do_restore_from_backup
his
read_write
HTML
delete_backup_after_restore
request
webapp
original_backup_info
required
writer
StringProperty
StartMap
minus
BOOLEAN
OAuth
kinds
IS
namespaces
embedded_entities_kind_iter
console
restore
whole
UserRPC
If
property_list
Optional
Type
ease
writing
BackupEntity
__get_property_type_info
requirements
get_access_token
ATOM_LINK
_ProcessPostRequest
path
blob_keys
primitive_type
AppEngine
PermissionDeniedError
relevant
_get_post_html_page
validation
_HandleException
task
into
KeyRangeEntityProtoIterator
params
minidom
suffix
proto
bucket_name
force_ops_writes
mapreduce_state
also
from_json
_internal
taskqueue_service_pb
Model
done_callback_queue
Unknown
Property
its
validate
shard_count
matches
iterkeys
datastore_backup_restore_
backup_info_file
boolean
redirected
RestoreEntity
copy
cls
contents
under
errorResponse
ImportError
entities
datastore_query
__init__
system
_queue
run_in_transaction
validate_and_canonicalize_gs_bucket
__needs_save
entity_type
RATING
indicates
apiproxy_errors
Base
BLOB
use
deferred
run
kind_filter
backup_information
Apache
Construct
check_success
get_kind_backup_files
size_total
EMAIL
usr
strftime
https
xsrf_token
transactional
dumps
embedded_entities
seen
TaskName
selected_kinds
repeated
either
_run_map_jobs_deferred
MAPREDUCE_DETAIL
admin
file_name_try
com
raw_property_list
Rendering
SchemaAggregationResult
overridable
_write_kind_backup_info_file
Validation
datastore
must
create_kind_backup_files_key
OUTPUT_WRITER
get_gs_object
RESTORE_COMPLETE_HANDLER
values
populate
ConfirmDeleteBackupHandler
Add
exclusive_lock
control
agreed
has_uservalue
issubset
SUFFIX
saved
complete_time
datastore_range_iterators
url
info_file
entity_schema
difference
datastore_backup_write_test
BaseException
entity_json
_write_kind_info
populate_entity_schema_field
listdir
__properties
INTEGER
Exception
can
notreadonly_warning
governing
www
BackupInformation
active_jobs
is_accessible_bucket_name
json
TEXT
multiple
output_writer_class
BACKUP_RESTORE_HANDLER
get_all
properties_json
__name__
Restore
FileRecordsOutputWriter
you
See
goog
anything
effect
registered
backup_info
actual
mismatch
Save
ReserveKey
tuple
selected_backup_info_file
confirm_backup_import
info
mapreduce_params
MAPREDUCE_MAX_SHARDS
DoBackupHandler
fname
startswith
DATE_TIME
Put
random
other_embedded_entity
PHONE_NUMBER
non
izip
displayed
start
now
__name
Restoring
Send
invoking
put
remove
indexed
link
__
initialized
mapping
remote_job_id
This
base_path
PrimitiveType
serialized
apphosting
RecordsReader
delete
Copyright
db_iters
module
_generate_filename
post
BlobInfo
MIN_BUCKET_LEN
ATOM_CATEGORY
entity_kind
ConfirmBackupImportHandler
env
len
already
__backup_id
folder
PropertyTypeInfo
bucketnaming
License
CapabilitySet
chain
original_app
STATUS_FAILED
Handler
Y_
end_timestamp
Could
backup_ids
All
backup_info_pk
bucket_element
used
GD_IM
DatetimeToTimestamp
namespace
BACKUP_COMPLETE_HANDLER
LICENSE
_transactional
longer
metadata
DateTimeProperty
BLOB_KEY
status
NotImplementedError
logging
format
strip
deleted
properties_name_iter
Storage
Z0
match
output
get_queue_names
state
file_name
task_retry_limit
parse_backup_info_file
Requested
pool
restore_from_backup
ConfirmRestoreFromBackupHandler
max_keys
exist
retrieved
getenv
ns_name
Abort
gs_bucket_name
ANY
file_content
_get_html_page
tasks
kind_files_models
appengine
utils
backup_kinds
Verify
target
special
started
SerializeToString
their
user
storage
get_blob_key
MAX_BUCKET_LEN
using
store
missing
shard_id
over
queue_name
has_booleanvalue
MAPREDUCE_PATH
fn
task_list
stringvalue
confirms
Retrieve
do_backup
parent
apiproxy_stub_map
requested
input_readers
isinstance
gs_handle
Failed
keeping
gs
GD_EMAIL
is_partial
__aggregation
handling
MAX_BUCKET_SEGMENT_LEN
remote_job
with_statement
could
Create
write
map
Merge
do
PUSH
datetime
ex
readable
transfers
may
Finalize
max
entity_pb
integer
needs
sharded_aggregation
Inc
ones
backing
is_enabled
starts
Split
APPLICATION_ID
exists
create_from_entity_proto
Get
IOError
classmethod
Unless
get_embedded_entity
blob_files
confirm_backup
docs
least
writable
GoogleApiScope
by
has_stringvalue
completion
close
__namespace__
KindBackupFiles
deal
optional
BASE_PATH
BackupLinkHandler
key
be
RequestTooLargeError
db
gen
get
BackupInfoWriter
BACKUP_HANDLER
parseString
blob_info
Return
force_writes
HTTP_X_APPENGINE_QUEUENAME
get_backup_files_tx
Entity
does
import_backup
ignored
get_mapper_params_from_context
Query
set
parse_gs_handle
Returns
get_filenames
SHORT_BLOB
Write
populates
redirect
gs_bucket
RunMapForKinds
Run
KIND
all
done_callback_handler
status_code
You
yields
enters
mapper_params
ids
at
is_readable_gs_handle
memory
_KEY_RANGE_ITER_CLS
message
Writes
create_kind_backup_files
an
mark_aggregation_as_partial_tx
backup_prefix_with_date
job_id
ns
MAX_TEST_FILENAME_TRIES
confirm_delete_backup
JsonProperty
operation
of
backup_kind
services_client
Remote
pending
confirmation
on
only
bucket_url
fetch
keys_only
os
op
done
deferred_task
kind_list
include
destination
pb
BaseDoHandler
them
Persistent
taskqueue
records
XSRF_ACTION
accessing
__gs_bucket
has_int64value
__call__
Deals
file_names
merge
randint
ValidateXsrfToken
WITHOUT
followed
mapreduce
m_
model_to_protobuf
Segment
CONDITIONS
ConfirmBackupHandler
Ids
backup
completed
files
delete_files
kind_files
persisted
sharded
Datastore
specified
persistent
itertools
ParseKindsAndSizes
queues
backup_id
filesystem
from_entity
count
form_target
make_call
queue_list
GD_PHONENUMBER
more
Unspecified
_GetBasicMapperParams
property_type_info
Process
when
value
get_property
embedded_schema
Missing
NUM_KINDS_DEFERRED_THRESHOLD
iterator
embedded_entity
cStringIO
environ
max_rows
datastore_v3
backup_name
called
BackupCompleteHandler
verify_bucket_writable
this
backup_prefix
datastore_admin_service
scope
embedded_entity_schema
get_backup_info
datastore_backup_
limitations
runtime
DatastoreEntityProtoInputReader
rstrip
applicable
add
was
id
StringIO
selected
job_list
read
accessible
blob_warning
start_timestamp
MAPREDUCE_MIN_SHARDS
application
TaskQueueFetchQueuesResponse
blob_key
extend
_retry_options
list
TaskQueueFetchQueuesRequest
to_json
BACKUP_INFORMATION_KIND_TYPE_INFO
name_exists
set_app_id
_perform_backup_complete
found
field_type
handle
Key
validate_gs_bucket_name
dom
list_bucket_files
schema
template_params
non_transactional
default_backup_id
finalize
backup_info_specified
__primitive_types
Bucket
iteritems
Handlers
Render
available
register_pool
BACKUP_INFORMATION_KIND
content
split
load
Cron
datastore_admin_home
Scheduled
selected_namespace
choice
bucket
next
data
Triggers
executed
The
defer
critical
datastore_types
Splits
kind_backup_files
selection
blobstore
field
replace
tx
get_pool
dest
devstorage
EntitySchema
string
doc
confirm
datastore_admin
Kinds
abort
keep
to
queue
detail
key_name
HTTP
AbortAdminOperation
after
cron
IM_HANDLE
tmp
ParsePartialFromString
parameters
Invalid
rfind
Version
instance
DEFERRED_PATH
Validate
auth_token
xml
size
that
input
reader
kind_backup_files_list
s_
str
associated
than
retry_options
result
sub
model
set_backup_info_with_finalize_info
GenerateHomeUrl
strings
re
kinds_backup_files
mapreduce_spec
POSTAL_ADDRESS
from_path
backups
ancestor
handlers_list
abort_backup
AggregateSchema
BooleanProperty
backup_suffix_counter
needed
SchemaAggregationPool
parent_key
Status
SendRedirect
py
invoke
listing
service
provided
html
operations
Google
STRING
out
handler
sizes_known
read_only
via
test
DoBackupImportHandler
app_identity
backup_pb2
Empty
open
are
page
file
__is_repeated
config
__embedded_entities
Redirects
Default
output_writer
information
RequestHandler
DoBackupRestoreHandler
update_aggregation_tx
create
has_meaning
MEANING_TO_PRIMITIVE_TYPE
RawDatastoreInputReader
record
obtain
ENTITY_PROTO
backup_files
primitive_types
app_id
language
Make
default_delete_backup_after_restore
has_pointvalue
non_empty_filenames
google
delete_backup_info
query
failed
encountered
Expected
Request
confirm_abort_backup
org
GD_RATING
kind
mode
version
backup_handler
union
length
api
_perform_backup
FromPb
min
app
responsible
_create_kind_backup
dictionary
access
developers
should
__entity_info
StartOperation
backup_delete
RecordsWriter
entity_proto
based
kind_info
backup_restore
Operation
job_operation_key
endswith
BackupInformationHandler
compliance
mapreduce_id
empty_file_keys
requests
json_util
were
BYTESTRING
blobstore_api
returns
custom
operation_name
property
properties
WARRANTIES
TypeError
Populates
default
backup_info_key
_run_map_jobs
TaskRetryOptions
RestoreCompleteHandler
filter
datastore_rpc
warn
dict
other
specific
have
one
get_kind_from_entity_pb
licenses
object
Creates
BackupValidationError
BACKUP_INFORMATION_FILES_KIND
displays
BLOBKEY
BackupInfo
FixKeys
REFERENCE
Args
shard
Licensed
max_jobs
error
entity_type_info
Yields
zA
the
BLOBSTORE_FILESYSTEM
BASIS
rules
_FromPb
job_name
Generic
context
start_time
filename
get_namespaces
bool
