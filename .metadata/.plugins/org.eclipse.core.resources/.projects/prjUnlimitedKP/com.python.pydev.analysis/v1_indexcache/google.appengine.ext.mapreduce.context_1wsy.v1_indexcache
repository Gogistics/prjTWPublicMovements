User
creates
shard_id
time
Increment
thread
objects
_largest
timed
basestring
number
__flush_function
_context_instance
isinstance
bin
each
MapReduce
A
before
unsaved
execution
_normalize_key
times
current
map
do
commits
define
readable
may
e
keys
a
Proto
Inc
Registers
i
new
t
utility
s
what
r
library
shard_state
Get
public
classmethod
Unless
sizes
_counters
entity_or_key
exception
entity
distributed
by
apache
accumulates
same
has
_LARGEST_ITEMS_TO_LOG
software
any
optional
permissions
key
be
get_shard_id
db
AS
append
RequestTooLargeError
get
MAX_ENTITY_COUNT
code
ndb
items
maximum
Return
_mutation_pool
example
force_writes
large
COUNTER_MAPPER_WALLTIME_MS
Entity
Mapreduce
Instead
Flush
Each
existing
COUNTER_MAPPER_CALLS
Returns
CreateConfig
name
implied
An
KIND
all
law
You
task_retry_count
at
DATASTORE_DEADLINE
main
__all__
input_reader
flush
see
an
ndb_deletes
DEFAULT_RETRIES
Whether
accessed
_db_repr
_create_config
Since
of
operation
ItemList
_ndb_repr
on
Currently
__repr_function
increment
Register
earlier
http
them
Will
then
recorded
will
auto
Flushing
holds
upon
mapper
express
WITHOUT
mapreduce
clear
CONDITIONS
OF
repr_function
heapq
ms
OR
_ToPb
hasattr
__max_entity_count
item
retry
warning
patch
_flush_ndb_deletes
apply
Timeout
single
mutations
second
Counters
_flush_puts
ext
any_argument
handlers
changed
buffer
python
Context
when
value
_local
Delete
required
writer
argument
such
int
IO
MyPool
IS
timeouts
Callers
called
If
this
Mutation
meaningful
__timeout_retries
mutation
runtime
writing
limitations
applicable
add
It
NDB
Regulates
zip
it
_flush_ndb_puts
task
into
list
params
counters_map
force_ops_writes
local
changes
Key
Model
flow
its
counters
retried
copy
cls
how
getattr
_populate_internal_entity
There
under
Obtains
ImportError
_set
mutation_pool
register_pool
entities
calls
log
__init__
organizes
deadline
apiproxy_errors
common
next
data
use
Clear
messages
The
Apache
datastore_types
_MutationPool
worker
usr
debugging
facilitate
max_entity_count
threading
Force
either
get_pool
_log_largest_items
string
slice
part
arbitrary
to
Upon
MapperSpec
perform
_ItemList
datastore
takes
values
care
Add
Set
instance
Version
agreed
so
Pool
saved
pools
logic
size
that
input
reader
str
associated
MapperWorkerHandler
nlargest
model
_flush_deletes
can
should_flush
governing
www
about
interpret
mapreduce_spec
undefined
functions
counter
provides
you
Configuration
See
needed
registered
invoke
Largest
flush_function
operations
Google
put_multi
_Counters
handler
out
aggregate
via
foo
repr
are
file
config
_normalize_entity
walltime
output_writer
information
Put
flushed
delta
actual_entity
largest
many
obtain
plug
flushes
language
ndb_puts
Config
bytes
google
put
_pools
org
This
mutates
Properties
length
delete
api
Copyright
end
options
let
env
len
access
should
License
successfully
OperationOnMyPool
Constructor
_to_pb
decides
but
Operation
All
compliance
Converts
together
been
function
mapreduce_id
LICENSE
puts
yielded
deletes
ndb_put
ShardState
delete_multi
logging
NotImplementedError
Like
WARRANTIES
flushing
representation
batch
contain
subclass
output
datastore_rpc
dict
Any
other
specific
one
MapreduceSpec
state
Got
object
licenses
purpose
turns
Creates
Args
shard
full
pool
callable
Licensed
For
counter_name
ANY
error
the
__str__
BASIS
ndb_delete
timeout_retries
_shard_state
appengine
specification
context
uses
bool
first
user
