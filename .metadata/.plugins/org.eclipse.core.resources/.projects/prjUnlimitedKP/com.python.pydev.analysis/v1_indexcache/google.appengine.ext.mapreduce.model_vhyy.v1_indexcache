chart_width
incompatible
particular
parts
creates
MapreduceState
__hooks
Raises
time
refer
Increment
urlencode
Causes
urllib
Do
from_request
Used
Maintains
unset
each
bin
big
spec
Logs
unique
HugeTaskHandler
A
relavent
times
Content
outputs
ensure
classes
g
d
e
keys
a
choices
chart_url
k
i
_RESULTS
new
t
including
s
r
base
testing
x
get_handler
drop
entity
mapper_output_writer
distributed
Payloads
input_reader_state
apache
has
software
basic
updated
description
permissions
processing
initial_input_reader_spec_dict
MAX_TASK_PAYLOAD
writer_state
AS
append
get_shard_id
execute
compressed_payload
display
Updates
processed
items
decode_payload
String
AE
active
module_name
update
_KEY_NAME
RESULT_SUCCESS
Contains
completely
TextProperty
possible
MapreduceControl
name
implied
get_processed
law
By
updates
depend
equal
counters_map_json
IntegerProperty
__all__
graphy
find_by_mapreduce_state
input_reader
which
source
retrieve
payload_str
Serializes
accessed
_get_mapreduce_spec
cached
jobs
lower
input_reader_spec_dict
verify
ByteStringProperty
Convert
errors
given
aggregated
carry
itself
gettime
increment
final
auto_now_add
enqueuing
job
MR
payload_entity
http
Will
will
holds
filters
indeed
JsonMixin
_GAE_MR_MapreduceState
base_handler
mapper
HugeTask
express
ValueError
PAYLOAD_PARAM
clear
unless
encoding
OF
Advance
kept
to_task
held
OR
per
method
octet
headers
integers
single
get_by_job_id
contains
type
try_serialize_handler
ext
changed
iteration
related
python
current_value
slice_start_time
request
webapp
ID
proceed
writer
required
StringProperty
Specifying
argument
new_value
Number
means
here
IS
mapper_input_reader
MapReduceSpec
GAE
shard_description
whole
If
util
_decode_payload
Type
writing
It
considered
corresponding
path
compute
_headers
BlobProperty
task
into
counters_map
params
database
get_hooks
implementation
mapreduce_state
timeout
from_json
_internal
mapper_shard_count
eta
Model
done_callback_queue
its
validate
shard_count
retried
matches
communicate
RESULT_ABORTED
boolean
entirely
copy
__repr__
cls
under
_COMMANDS
model_class_path
always
entities
log
__init__
bottom
output_writer_state
active_shards
specify
set_for_abort
initial_map
sort
set_for_success
use
states
expensive
Clear
run
messages
Apache
_GAE_MR_ShardState
truth
immutable
best
usr
correctness
transactional
Decode
either
to_dict
chart
retries
Generate
progress
Upon
MapperSpec
ended
for_name
datastore
must
result_status
shards
values
Add
hooks_class_name
control
agreed
loads
Gets
saved
period
url
failure
instantiated
got
valid
can
expectation
governing
www
incremented
kwargs
So
json
output_writer_class
Payload
counter
__name__
sorted
_get_descending_key
you
See
TransientShardState
subtract
counted
ordered
actual
Integer
Some
expired
everything
info
Url
Init
startswith
slice_id
_GAE_MR_TaskPayload
like
get_shard_number
huge
many
now
ASAP
DatastoreInputReader
some
Use
frozenset
stream
put
range
remove
indexed
xrange
This
Properties
according
base_path
serialized
starting
Copyright
Dictionary
end
__payload
just
entity_kind
Holds
prop
len
env
stored
framework
shard_number
process
_attempt_slice_recovery
License
failed_shards
initial_input_reader_state
mapper_handler_spec
successfully
find_all_by_mapreduce_state
allowed
send
transaction
from_json_str
adds
All
used
set_for_failure
been
function
LICENSE
doesn
sent
cgi
handler_for_name
decompress
DateTimeProperty
status
format
Only
wants
update_time
They
representation
output
setattr
state
Json
output_writer_spec
KickOffJob
pickled
encoded
Copy
buil
because
controls
API
another
details
callable
aborted
exist
beginning
ANY
done_callback
tasks
Not
around
Job
appengine
hooks_class
BarChart
instead
other_state
started
total
need
said
backends
store
Single
shard_id
queue_name
references
mapper_spec
once
parent
number
izable
isinstance
handler_spec
before
instances
PARAM_DONE_CALLBACK_QUEUE
execution
reset_for_retry
Create
computed
map
current
write
_input_reader_json
left
do
datetime
deprecated
may
max
needs
web
Inc
starts
exists
Get
get_by_key_name
classmethod
returned
Unless
bound
body
last_work_item
constructed
least
BaseConnection
by
splitting
Encapsulates
same
long
any
accumulated
key
be
db
PAYLOAD_VERSION_HEADER
get
manually
compress
lease
containing
example
phase
issubclass
Mapreduce
set
add_map
COUNTER_MAPPER_CALLS
Returns
get_filenames
KIND
types
all
parallel
You
communication
mapper_params
method_name
at
still
PAYLOAD_KEY_PARAM
memory
see
Calculate
an
ns
no
advance_for_next_slice
JsonProperty
MAX_PUSH_TASK_SIZE_BYTES
of
verified
only
on
new_mapreduce_id
fully
keys_only
fetch
structure
done
DeprecationWarning
to_json_str
committed
then
taskqueue
small
calculate_keys_by_mapreduce_state
__call__
Taskqueue
WITHOUT
mapreduce
CONDITIONS
files
mr
JSON
CounterMap
batch_size
succeeds
Datastore
specified
additional
item
within
retry
_GAE_MR_MapreduceControl
qualified
staticmethod
individual
last
count
save
remains
handlers
more
when
value
MAX_RPC_BYTES
Subtracts
create_new
int
kv
inherit
describing
called
executing
controller
this
release
sparkline_url
shard_id_from_number
hooks
no_tx_get
limitations
way
add
applicable
was
id
read
Mirrors
between
application
it
compressed_payload_str
readers
list
input_reader_spec
two
to_json
duration
get_by_shard_id
removed
wrong
Compute
found
These
Key
passed
don
ready
counters
payload_key
urlencoding
non_transactional
finalize
memcache
duplicates
getattr
__class__
When
grace
Task
load
own
split
we
parse_qs
set_processed_counts
next
data
auto_now
running
The
critical
duplicated
serialized_handler
older
payloads
__eq__
PAYLOAD_VERSION
RESULT_FAILED
later
slice_request_id
field
MAX_DB_PAYLOAD
string
doc
slice
recovery_slice
sub_map
part
abort
to
queue
provide
key_name
acquired_once
after
__payload_key
conservative
function_name
parameters
instance
Version
labels
reduce
logic
arithmetics
that
finish
input
reader
str
generated
due
deserialized
result
model
about
get_key_by_job_id
stride_length
mapreduce_spec
Shard
PARAM_DONE_CALLBACK
from_path
try_deserialize_handler
MapperWorkerCallbackHandler
compatible
too
_MAX_STATES_IN_MEMORY
mr_id
DEFAULT_BATCH_SIZE
BooleanProperty
needed
recovery
_payload
determined
Google
success
During
handler
Reset
QuerySpec
subtracts
payload
whether
filled
aborted_shards
are
fail
shards_processed
initial
file
output_writer
form
delta
create
OutputWriter
obtain
Controller
CountersMap
zlib
ABORT
app_id
language
Retrieves
input_reader_class
google
query
failed
Request
class_name
org
kind
version
Deprecated
Hooks
command
api
acquired
Please
min
app
slice_retries
get_key_by_shard_id
logs
polled
dictionary
should
Constructor
simplejson
old
kill
compliance
google_chart_api
mapreduce_id
json_util
yielded
last_poll_time
Initial
ShardState
work
Find
property
properties
WARRANTIES
countdown
default
JsonDecoder
subclass
even
rest
management
datastore_rpc
dict
other
allow
specific
have
one
MapreduceSpec
licenses
object
Creates
_HugeTaskPayload
displays
Args
shard
during
Licensed
Huge
For
How
copy_from
counter_name
ShardStates
lock
Yields
the
_MAP_REDUCE_KINDS
__str__
BASIS
Datatore
spec_json
initial_input_reader
specification
context
start_time
